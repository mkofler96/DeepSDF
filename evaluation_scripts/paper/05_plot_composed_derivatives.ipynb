{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gustaf as gus\n",
    "import splinepy as sp\n",
    "import vedo\n",
    "\n",
    "import os\n",
    "os.chdir(\"/home/michael.kofler/DeepSDF\")\n",
    "\n",
    "vedo.settings.default_backend = 'k3d'\n",
    "\n",
    "from sdf_sampler.plotting import scatter_contour_at_z_level\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from deep_sdf import workspace as ws\n",
    "import deep_sdf.utils\n",
    "import pathlib\n",
    "\n",
    "import igl\n",
    "\n",
    "params = {'text.usetex': False, 'mathtext.fontset': 'cm', 'axes.labelsize': 12}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_directory = \"experiments/double_lattice_3D\"\n",
    "checkpoint = \"1000\"\n",
    "\n",
    "graded = True\n",
    "\n",
    "latent = ws.load_latent_vectors(experiment_directory, checkpoint).to(\"cpu\").numpy()\n",
    "decoder = ws.load_trained_model(experiment_directory, checkpoint).to(device)\n",
    "decoder.eval()\n",
    "latent_base = np.array([0, -0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_points_ungraded = np.array([latent_base]*4)\n",
    "control_points_graded = control_points_ungraded\n",
    "# control_points_graded[3] += 0.2\n",
    "\n",
    "tiling = [2, 2, 1]\n",
    "N_base = 20\n",
    "\n",
    "\n",
    "control_points_for_min_max = np.vstack([control_points_graded, control_points_ungraded])\n",
    "\n",
    "if graded:\n",
    "    graded_string = \"_single_graded_derivative\"\n",
    "    control_points = np.vstack([control_points_graded, control_points_graded])\n",
    "else:\n",
    "    graded_string = \"_single\"\n",
    "    control_points = np.vstack([control_points_ungraded, control_points_ungraded])\n",
    "\n",
    "latent_vec_interpolation = sp.BSpline(\n",
    "    degrees=[1, 1, 1],\n",
    "    knot_vectors=[[-1, -1, 1, 1], \n",
    "                [-1, -1, 1, 1], \n",
    "                [-1, -1, 1, 1]],\n",
    "    control_points=control_points,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform(x, t):\n",
    "    p = 2/t\n",
    "    return (2/p)*torch.abs((x-t%2) % (p*2) - p) -1 \n",
    "\n",
    "def sdf_struct(queries):\n",
    "    queries = torch.tensor(queries, dtype=torch.float32).to(device)\n",
    "    tx, ty, tz = tiling\n",
    "\n",
    "\n",
    "    samples = torch.zeros(queries.shape[0], 3)\n",
    "    samples[:, 0] = transform(queries[:, 0], tx)\n",
    "    samples[:, 1] = transform(queries[:, 1], ty)\n",
    "    samples[:, 2] = transform(queries[:, 2], tz)\n",
    "    lat_vec_red = torch.tensor(latent_vec_interpolation.evaluate(queries.cpu().numpy()), dtype=torch.float32)\n",
    "    queries = torch.hstack([torch.tensor(lat_vec_red).to(torch.float32).to(device), samples])\n",
    "\n",
    "    return deep_sdf.utils.decode_sdf(decoder, None, queries).squeeze(1).detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling takes: 0.145322\n",
      "sampling takes: 0.198087\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.74 GiB. GPU 0 has a total capacty of 47.43 GiB of which 3.75 GiB is free. Including non-PyTorch memory, this process has 43.67 GiB memory in use. Of the allocated memory 38.51 GiB is allocated by PyTorch, and 4.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m cap_border_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx0\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcap\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m},\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcap\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m},\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my0\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcap\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m},\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my1\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcap\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasure\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m},\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      8\u001b[0m N \u001b[38;5;241m=\u001b[39m [N_base \u001b[38;5;241m*\u001b[39m t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tiling]\n\u001b[0;32m---> 10\u001b[0m verts, faces, jac \u001b[38;5;241m=\u001b[39m \u001b[43mdeep_sdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_mesh_microstructure_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtiling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_vec_interpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcap_border_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcap_border_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_derivatives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m jac \u001b[38;5;241m=\u001b[39m jac\u001b[38;5;241m.\u001b[39mreshape((jac\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], jac\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     12\u001b[0m verts_np \u001b[38;5;241m=\u001b[39m verts\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/DeepSDF/deep_sdf/mesh.py:450\u001b[0m, in \u001b[0;36mcreate_mesh_microstructure_diff\u001b[0;34m(tiling, decoder, latent_vec_interpolation, N, max_batch, offset, scale, cap_border_dict, device, output_tetmesh, compute_derivatives)\u001b[0m\n\u001b[1;32m    446\u001b[0m tot_jac \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_derivatives:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# this is wrong: this computes the jacobian with respect to the sdf values, not the latent vector\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;66;03m# todo: refactor this whole function and compute the jacobian with respect to the latent vector\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m     jac \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat_vec_red\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     basis_eval \u001b[38;5;241m=\u001b[39m latent_vec_interpolation\u001b[38;5;241m.\u001b[39mbasis(np\u001b[38;5;241m.\u001b[39mclip(samples_orig[:, :\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# slow version\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# for i in range(jac.shape[3]):\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m#     tot_jac.append(np.matmul(jac.detach().cpu().numpy()[:,:,:,i], basis_eval))\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;66;03m# tot_jac = np.dstack(tot_jac)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/functional.py:818\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    814\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    815\u001b[0m                 jac_i_el\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mzeros_like(inp_el))\n\u001b[1;32m    817\u001b[0m     jacobian \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 818\u001b[0m         \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_i_el\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mel_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[operator]\u001b[39;49;00m\n\u001b[1;32m    821\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mel_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac_i_el\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjac_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    824\u001b[0m     )\n\u001b[1;32m    826\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m _grad_postprocess(jacobian, create_graph)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(jacobian, (is_outputs_tuple, is_inputs_tuple))\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/functional.py:819\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    814\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    815\u001b[0m                 jac_i_el\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mzeros_like(inp_el))\n\u001b[1;32m    817\u001b[0m     jacobian \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 819\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_i_el\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    820\u001b[0m                 out\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m+\u001b[39m inputs[el_idx]\u001b[38;5;241m.\u001b[39msize()  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    821\u001b[0m             )\n\u001b[1;32m    822\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m (el_idx, jac_i_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(jac_i)\n\u001b[1;32m    823\u001b[0m         ),\n\u001b[1;32m    824\u001b[0m     )\n\u001b[1;32m    826\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m _grad_postprocess(jacobian, create_graph)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(jacobian, (is_outputs_tuple, is_inputs_tuple))\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.74 GiB. GPU 0 has a total capacty of 47.43 GiB of which 3.75 GiB is free. Including non-PyTorch memory, this process has 43.67 GiB memory in use. Of the allocated memory 38.51 GiB is allocated by PyTorch, and 4.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "cap_border_dict = {\n",
    "    \"x0\": {\"cap\": 1, \"measure\": 0.1},\n",
    "    \"x1\": {\"cap\": 1, \"measure\": 0.1},\n",
    "    \"y0\": {\"cap\": 1, \"measure\": 0.1},\n",
    "    \"y1\": {\"cap\": 1, \"measure\": 0.1},\n",
    "}\n",
    "\n",
    "N = [N_base * t+1 for t in tiling]\n",
    "\n",
    "verts, faces, jac = deep_sdf.mesh.create_mesh_microstructure_diff(tiling, decoder, latent_vec_interpolation, cap_border_dict=cap_border_dict, N=N, device=device, compute_derivatives=True)\n",
    "jac = jac.reshape((jac.shape[0], jac.shape[1], -1))\n",
    "verts_np = verts.detach().cpu().numpy()\n",
    "faces_np = faces.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a8f30533d84ea7bcecee39175fd50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "K3DPlotterN(children=(Plot(antialias=True, axes=['x', 'y', 'z'], axes_helper=1.0, axes_helper_colors=[16711680â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "faces = []\n",
    "jac[np.where(jac>1)] = 0\n",
    "jac[np.where(jac<-1)] = 0\n",
    "for i in range(jac.shape[2]):\n",
    "    faces_der1 = gus.Faces(verts_np, faces_np)\n",
    "    directions = jac\n",
    "    positions = verts_np\n",
    "    faces_der1.vertex_data[\"directions\"] = jac[:,:,i]\n",
    "    faces_der1.show_options[\"arrow_data\"] = \"directions\"\n",
    "    faces.append(faces_der1)\n",
    "gus.show(*faces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.038772617134522e-05\n"
     ]
    }
   ],
   "source": [
    "print(jac.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
